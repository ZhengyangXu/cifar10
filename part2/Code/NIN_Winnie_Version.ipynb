{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "\n",
    "## import our module\n",
    "import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all the output \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has apparently already been downloaded and unpacked.\n"
     ]
    }
   ],
   "source": [
    "cifar10.maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: data/CIFAR-10/cifar-10-batches-py/batches.meta\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = cifar10.load_class_names()\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_1\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_2\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_3\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_4\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_5\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/test_batch\n"
     ]
    }
   ],
   "source": [
    "images_train, cls_train, labels_train = cifar10.load_training_data()\n",
    "images_test, cls_test, labels_test = cifar10.load_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only for checking purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "######only for checking purpose\n",
    "images_train = images_train[0:5000,:,:,:]\n",
    "labels_train = labels_train[0:5000,:]\n",
    "\n",
    "images_test = images_test[0:1000,:,:,:]\n",
    "labels_test= labels_test[0:1000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 32, 32, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1000, 32, 32, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(5000, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data shape \n",
    "images_train.shape\n",
    "images_test.shape\n",
    "labels_train.shape   ##label_train and test_train is the one-hot coded label \n",
    "labels_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Different help-Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. For pre-process image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_image(image, training):\n",
    "    # This function takes a single image as input,\n",
    "    # and a boolean whether to build the training or testing graph.\n",
    "    \n",
    "    if training:\n",
    "        # For training, add the following to the TensorFlow graph.\n",
    "\n",
    "        # Randomly crop the input image.\n",
    "        image = tf.random_crop(image, size=[img_size_cropped, img_size_cropped, num_channels])\n",
    "\n",
    "        # Randomly flip the image horizontally.\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        \n",
    "        # Randomly adjust hue, contrast and saturation.\n",
    "        image = tf.image.random_hue(image, max_delta=0.05)\n",
    "        image = tf.image.random_contrast(image, lower=0.3, upper=1.0)\n",
    "        image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "        image = tf.image.random_saturation(image, lower=0.0, upper=2.0)\n",
    "\n",
    "        # Some of these functions may overflow and result in pixel\n",
    "        # values beyond the [0, 1] range. It is unclear from the\n",
    "        # documentation of TensorFlow 0.10.0rc0 whether this is\n",
    "        # intended. A simple solution is to limit the range.\n",
    "\n",
    "        # Limit the image pixels between [0, 1] in case of overflow.\n",
    "        image = tf.minimum(image, 1.0)\n",
    "        image = tf.maximum(image, 0.0)\n",
    "    else:\n",
    "        # For training, add the following to the TensorFlow graph.\n",
    "\n",
    "        # Crop the input image around the centre so it is the same\n",
    "        # size as images that are randomly cropped during training.\n",
    "        image = tf.image.resize_image_with_crop_or_pad(image,\n",
    "                                                       target_height=img_size_cropped,\n",
    "                                                       target_width=img_size_cropped)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def pre_process(images, training):\n",
    "    # Use TensorFlow to loop over all the input images and call\n",
    "    # the function above which takes a single image as input.\n",
    "    images = tf.map_fn(lambda image: pre_process_image(image, training), images)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. For get the cross entropy and the accuracy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The teo functions are from script for class\n",
    "def compute_cross_entropy(logits, y):\n",
    "    # Compute the average cross-entropy across all the examples.\n",
    "    numerical_instability_example = 0\n",
    "    if numerical_instability_example:\n",
    "        y_pred = tf.nn.softmax(logits, name='y_pred') # the predicted probability for each example.\n",
    "        cross_ent = tf.reduce_mean(-tf.reduce_sum(y * tf.log(y_pred), reduction_indices=[1]))\n",
    "    else:\n",
    "        sm_ce = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits, name='cross_ent_terms')\n",
    "        cross_ent = tf.reduce_mean(sm_ce, name='cross_ent')\n",
    "    return cross_ent\n",
    "\n",
    "def compute_accuracy(logits, y):\n",
    "    prediction = tf.argmax(logits, 1, name='pred_class')\n",
    "    true_label = tf.argmax(y, 1, name='true_class')\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, true_label), tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. For better training the network\n",
    "#### But we don't use it for the new version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _variable_with_weight_decay(name, shape, stddev, wd):\n",
    "\t\"\"\"\n",
    "\tHelper to create an initialized Variable with weight decay\n",
    "\n",
    "\tArgs:\n",
    "\t\tname: name of the variable\n",
    "\t\tshape: list of ints\n",
    "\t\tstddev: standard deviation of a truncated Gaussian\n",
    "\t\twd: add L2Loss weight decay multiplied by this float. If None, weight\n",
    "\t\t\tdecay is not added for this Variable.\n",
    "\n",
    "\tReturns:\n",
    "\t\tVariable Tensor\n",
    "\t\"\"\"\n",
    "\tvar = _variable_on_cpu_(\n",
    "\t\tname,\n",
    "\t\tshape,\n",
    "\t\ttf.truncated_normal_initializer(stddev=stddev, dtype=tf.float32))\n",
    "\tif wd is not None:\n",
    "\t\tweight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "\t\ttf.add_to_collection('losses', weight_decay)\n",
    "\treturn var\n",
    "\n",
    "\n",
    "def _variable_on_cpu_(name, shape, initializer):\n",
    "\t\"\"\"\n",
    "\tHelper to create a Variable stored on CPU memory\n",
    "\n",
    "\tArgs:\n",
    "\t\tname: name of the variable\n",
    "\t\tshape: list of ints\n",
    "\t\tinitializer: initializer for Variable\n",
    "\n",
    "\tReturns:\n",
    "\t\tVariable Tensor\n",
    "\n",
    "\t\"\"\"\n",
    "\twith tf.device('/cpu:0'):\n",
    "\t\tvar = tf.get_variable(name, shape, initializer=initializer, dtype=tf.float32)\n",
    "\treturn var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.  For defining the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(x, W):\n",
    "    \"\"\"simple wrapper for tf.nn.conv2d\"\"\"\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def maxpool(x):\n",
    "    \"\"\"simple wrapper for tf.nn.max_pool with kernel size 3, stride size 2\"\"\"\n",
    "    return tf.nn.max_pool(x, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def avgpool(x, k = 3, s = 2, p = 'SAME'):\n",
    "    \"\"\"simple wrapper for tf.nn.max_pool with kernel size 3, stride size 2\"\"\"\n",
    "    return tf.nn.avg_pool(x, ksize=[1, k, k, 1], strides=[1, s, s, 1], padding= p)\n",
    "\n",
    "def dropout(x):\n",
    "    \"\"\"simple wrapper for tf.nn.dropout with dropout ratio 0.5\"\"\"\n",
    "    return tf.nn.dropout(x, 0.5)\n",
    "    \n",
    "\n",
    "def compute_logits(x):\n",
    "    x_image = tf.reshape(x, [-1, 32, 32, 3])\n",
    "    # conv1 / relu1\n",
    "    W_conv1 = tf.get_variable('W_conv1', shape = [5, 5, 3, 192])\n",
    "    b_conv1 = tf.get_variable('b_conv1', shape = [192])\n",
    "    h_conv1 = tf.nn.relu(tf.add(conv(x_image, W_conv1), b_conv1))\n",
    "    #print(h_conv1)\n",
    "    #print(\"fucccccccccccccccccccccccccck\")\n",
    "    # cccp1 / relu_cccp1\n",
    "    W_cccp1 = tf.get_variable('W_cccp1', shape = [1, 1, 192, 160])\n",
    "    b_cccp1 = tf.get_variable('b_cccp1', shape = [160])\n",
    "    h_cccp1 = tf.nn.relu(tf.add(conv(h_conv1, W_cccp1), b_cccp1))\n",
    "    # cccp2 / relu_cccp2\n",
    "    W_cccp2 = tf.get_variable('W_cccp2', shape = [1, 1, 160, 96])\n",
    "    b_cccp2 = tf.get_variable('b_cccp2', shape = [96])\n",
    "    h_cccp2 = tf.nn.relu(tf.add(conv(h_cccp1, W_cccp2), b_cccp2))\n",
    "    #print(h_cccp2)\n",
    "    # pool\n",
    "    h_pool1 = maxpool(h_cccp2)\n",
    "   # print(h_cccp2)\n",
    "    # drop3\n",
    "    h_drop3 = dropout(h_pool1)\n",
    "    # conv2 / relu2\n",
    "    W_conv2 = tf.get_variable('W_conv2', shape = [5, 5, 96, 192])\n",
    "    b_conv2 = tf.get_variable('b_conv2', shape = [192])\n",
    "    h_conv2 = tf.nn.relu(tf.add(conv(h_drop3, W_conv2), b_conv2))\n",
    "    # cccp3 / relu_cccp3\n",
    "    #W_cccp3 = tf.get_variable('W_cccp3', shape = [1, 1, 192, 192])\n",
    "    #b_cccp3 = tf.get_variable('b_cccp3', shape = [192])\n",
    "    #h_cccp3 = tf.nn.relu(tf.add(conv(h_conv2, W_cccp3), b_cccp3))\n",
    "    # cccp4 / relu_cccp4\n",
    "    #W_cccp4 = tf.get_variable('W_cccp4', shape = [1, 1, 192, 192])\n",
    "    #b_cccp4 = tf.get_variable('b_cccp4', shape = [192])\n",
    "    #h_cccp4 = tf.nn.relu(tf.add(conv(h_cccp3, W_cccp4), b_cccp4))\n",
    "    # poo2\n",
    "    #h_pool2 = avgpool(h_cccp4)\n",
    "    h_pool2 = avgpool(h_conv2)\n",
    "    # drop6\n",
    "    h_drop6 = dropout(h_pool2)\n",
    "    # conv3 / relu3\n",
    "    W_conv3 = tf.get_variable('W_conv3', shape = [3, 3, 192, 192])\n",
    "    b_conv3 = tf.get_variable('b_conv3', shape = [192])\n",
    "    h_conv3 = tf.nn.relu(tf.add(conv(h_drop6, W_conv3), b_conv3))\n",
    "    # cccp5 / relu_cccp5\n",
    "    W_cccp5 = tf.get_variable('W_cccp5', shape = [1, 1, 192, 192])\n",
    "    b_cccp5 = tf.get_variable('b_cccp5', shape = [192])\n",
    "    h_cccp5 = tf.nn.relu(tf.add(conv(h_conv3, W_cccp5), b_cccp5))\n",
    "    # cccp6 / relu_cccp6\n",
    "    W_cccp6 = tf.get_variable('W_cccp6', shape = [1, 1, 192, 10])\n",
    "    b_cccp6 = tf.get_variable('b_cccp6', shape = [10])\n",
    "    h_cccp6 = tf.nn.relu(tf.add(conv(h_cccp5, W_cccp6), b_cccp6))\n",
    "    # pool3\n",
    "    h_pool3 = avgpool(h_cccp6, 8, 1, 'VALID')\n",
    "    output_reshaped = tf.reshape(h_pool3, [-1,10])\n",
    "\n",
    "    #print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "   # print(output_reshaped.shape)\n",
    "    return output_reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. for Beting the random batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch():\n",
    "    # Number of images in the training-set.\n",
    "    num_images = len(images_train)\n",
    "\n",
    "    # Create a random index.\n",
    "    idx = np.random.choice(num_images,\n",
    "                           size=batch_size,\n",
    "                           replace=False)\n",
    "\n",
    "    # Use the random index to select random images and labels.\n",
    "    x_batch = images_train[idx, :, :, :]\n",
    "    y_batch = labels_train[idx, :]\n",
    "\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load the size and cropped size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar10 import img_size, num_channels, num_classes\n",
    "img_size_cropped = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size\n",
    "num_channels\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = \"./log/\"\n",
    "batch_size = 128\n",
    "num_iterations = 20000 \n",
    "opt_method = 'adam'\n",
    "\n",
    "# Global constants describing the CIFAR-10 data set.\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000\n",
    "\n",
    "# Constants descrbing the training process.\n",
    "MOVING_AVERAGE_DEVAY = 0.9999 # The dacay to use for moving average\n",
    "NUM_EPOCHES_PER_DECAY = 350.0 # Epochs after which learning rate decays.\n",
    "LEARNING_RATE_DECAY_FACTOR = 0.1 # Learning rate decat factor.\n",
    "INITIAL_LEARNING_RATE = 0.1 # Initial learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Randomly Chroped the test and training image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train_chorped = pre_process(images_train, training=True)\n",
    "images_test_chorped = pre_process(images_test,training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(5000), Dimension(32), Dimension(32), Dimension(3)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train_chorped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'summaries/loss:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'summaries/accuracy:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'summaries/logits:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'summaries/input:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-0'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   0: training accuracy 0.1094\n",
      "Step   0: val accuracy 0.1120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-200'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200: training accuracy 0.1797\n",
      "Step 200: val accuracy 0.2140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-400'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400: training accuracy 0.2109\n",
      "Step 400: val accuracy 0.2360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-600'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600: training accuracy 0.3281\n",
      "Step 600: val accuracy 0.2830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-800'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 800: training accuracy 0.3438\n",
      "Step 800: val accuracy 0.3600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-1000'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000: training accuracy 0.3359\n",
      "Step 1000: val accuracy 0.3640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-1200'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1200: training accuracy 0.3984\n",
      "Step 1200: val accuracy 0.3900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-1400'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1400: training accuracy 0.4688\n",
      "Step 1400: val accuracy 0.3840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-1600'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1600: training accuracy 0.4219\n",
      "Step 1600: val accuracy 0.4070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-1800'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1800: training accuracy 0.4219\n",
      "Step 1800: val accuracy 0.4200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-2000'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2000: training accuracy 0.4609\n",
      "Step 2000: val accuracy 0.4260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-2200'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2200: training accuracy 0.4375\n",
      "Step 2200: val accuracy 0.4300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-2400'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2400: training accuracy 0.5156\n",
      "Step 2400: val accuracy 0.4370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-2600'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2600: training accuracy 0.3906\n",
      "Step 2600: val accuracy 0.4440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-2800'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2800: training accuracy 0.4141\n",
      "Step 2800: val accuracy 0.4320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-3000'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3000: training accuracy 0.4844\n",
      "Step 3000: val accuracy 0.4480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-3200'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3200: training accuracy 0.5156\n",
      "Step 3200: val accuracy 0.4620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-3400'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3400: training accuracy 0.3828\n",
      "Step 3400: val accuracy 0.4490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-3600'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3600: training accuracy 0.4141\n",
      "Step 3600: val accuracy 0.4810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-3800'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3800: training accuracy 0.4688\n",
      "Step 3800: val accuracy 0.4590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-4000'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4000: training accuracy 0.4531\n",
      "Step 4000: val accuracy 0.4660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-4200'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4200: training accuracy 0.5625\n",
      "Step 4200: val accuracy 0.4760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-4400'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4400: training accuracy 0.5234\n",
      "Step 4400: val accuracy 0.4840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-4600'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4600: training accuracy 0.4922\n",
      "Step 4600: val accuracy 0.4770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-4800'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4800: training accuracy 0.6172\n",
      "Step 4800: val accuracy 0.4760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-5000'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5000: training accuracy 0.4688\n",
      "Step 5000: val accuracy 0.4810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-5200'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5200: training accuracy 0.5000\n",
      "Step 5200: val accuracy 0.4810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-5400'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5400: training accuracy 0.5469\n",
      "Step 5400: val accuracy 0.4880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-5600'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5600: training accuracy 0.5859\n",
      "Step 5600: val accuracy 0.4990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-5800'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5800: training accuracy 0.4766\n",
      "Step 5800: val accuracy 0.4780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-6000'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6000: training accuracy 0.5547\n",
      "Step 6000: val accuracy 0.4860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-6200'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6200: training accuracy 0.5703\n",
      "Step 6200: val accuracy 0.4960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-6400'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6400: training accuracy 0.5078\n",
      "Step 6400: val accuracy 0.4800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-6600'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6600: training accuracy 0.5078\n",
      "Step 6600: val accuracy 0.4760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-6800'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6800: training accuracy 0.6016\n",
      "Step 6800: val accuracy 0.4830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-7000'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7000: training accuracy 0.5547\n",
      "Step 7000: val accuracy 0.4770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-7200'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7200: training accuracy 0.5469\n",
      "Step 7200: val accuracy 0.4980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-7400'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7400: training accuracy 0.5547\n",
      "Step 7400: val accuracy 0.5050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-7600'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7600: training accuracy 0.6328\n",
      "Step 7600: val accuracy 0.4970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/model_iter-7800'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7800: training accuracy 0.5625\n",
      "Step 7800: val accuracy 0.5150\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-33caf44c1fdb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[1;31m# now run\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m                 _ , summary = sess.run((train_step, summary_op),\n\u001b[1;32m---> 57\u001b[1;33m                                       feed_dict={x: X_batch, y_true: y_batch})\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[1;31m# write the summary output to file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\AdvML\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\AdvML\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\AdvML\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\AdvML\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\AdvML\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    \n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    # Get images and labels for CIFAR-10.\n",
    "    # Force input pipeline to CPU:0 to avoid operations sometimes ending up on\n",
    "    # GPU and resulting in a slow down.\n",
    "    with tf.device('/cpu:0'):\n",
    "        \n",
    "        # We build the model here as before\n",
    "        x = tf.placeholder(tf.float32, shape=[None, img_size_cropped, img_size_cropped, num_channels], name='x')\n",
    "        y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "        #print('y_true size: ', y_true.shape)\n",
    "        \n",
    "        with tf.name_scope('model'):\n",
    "            logits = compute_logits(x)\n",
    "        with tf.name_scope('loss'):\n",
    "            loss = compute_cross_entropy(logits=logits, y=y_true)\n",
    "        with tf.name_scope('accuracy'):\n",
    "            accuracy = compute_accuracy(logits, y_true)\n",
    "        \n",
    "        with tf.name_scope('opt'):   \n",
    "            if opt_method == 'sgd':\n",
    "                opt = tf.train.GradientDescentOptimizer(0.5)\n",
    "            elif opt_method == 'rms':\n",
    "                opt = tf.train.RMSPropOptimizer(.001)\n",
    "            elif opt_method == 'adam':\n",
    "                opt = tf.train.AdamOptimizer(1e-4)\n",
    "            train_step = opt.minimize(loss)\n",
    "    \n",
    "        with tf.name_scope('summaries'):\n",
    "            # create summary for loss and accuracy\n",
    "            tf.summary.scalar('loss', loss) \n",
    "            tf.summary.scalar('accuracy', accuracy)\n",
    "            # create summary for logits\n",
    "            tf.summary.histogram('logits', logits)\n",
    "            # create summary for input image\n",
    "            tf.summary.image('input', tf.reshape(x, [-1,img_size_cropped,img_size_cropped, num_channels]))\n",
    "    \n",
    "            summary_op = tf.summary.merge_all()\n",
    "    \n",
    "        saver = tf.train.Saver()    ##Save the model\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            summary_writer = tf.summary.FileWriter(dir_name, sess.graph)\n",
    "            summary_writer_train = tf.summary.FileWriter(dir_name+'/train', sess.graph)\n",
    "            summary_writer_val = tf.summary.FileWriter(dir_name+'/val')\n",
    "        \n",
    "            sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "            for i in range(num_iterations):\n",
    "                X_batch, y_batch = random_batch()\n",
    "\n",
    "            # now run\n",
    "                _ , summary = sess.run((train_step, summary_op),\n",
    "                                      feed_dict={x: X_batch, y_true: y_batch})\n",
    "                \n",
    "            # write the summary output to file\n",
    "                if i%200==0:\n",
    "                    saver.save(sess, './model/model_iter', global_step=i)\n",
    "                    \n",
    "                    summary_writer_train.add_summary(summary, i)\n",
    "                    \n",
    "                    (train_error,train_logits) = sess.run((accuracy,logits), {x: X_batch, y_true: y_batch})\n",
    "                    print(\"\\rStep {0:3d}: training accuracy {1:0.4f}\".format(i, train_error), flush=True)\n",
    "                \n",
    "                    X_batch2 = images_test\n",
    "                    y_batch2 = labels_test\n",
    "                    (val_error, summary) = sess.run((accuracy,summary_op), {x:X_batch2, y_true:y_batch2})\n",
    "                    print(\"\\rStep {0:3d}: val accuracy {1:0.4f}\".format(i, val_error), flush=True)\n",
    "                    summary_writer_val.add_summary(summary, i)\n",
    "        \n",
    "        # Save the final model\n",
    "        save_path = saver.save(sess, \"./model/model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the Imgae**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None, smooth=True):\n",
    "\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "\n",
    "    # Create figure with sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "\n",
    "    # Adjust vertical spacing if we need to print ensemble and best-net.\n",
    "    if cls_pred is None:\n",
    "        hspace = 0.3\n",
    "    else:\n",
    "        hspace = 0.6\n",
    "    fig.subplots_adjust(hspace=hspace, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Interpolation type.\n",
    "        if smooth:\n",
    "            interpolation = 'spline16'\n",
    "        else:\n",
    "            interpolation = 'nearest'\n",
    "\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i, :, :, :],\n",
    "                  interpolation=interpolation)\n",
    "            \n",
    "        # Name of the true class.\n",
    "        cls_true_name = class_names[cls_true[i]]\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true_name)\n",
    "        else:\n",
    "            # Name of the predicted class.\n",
    "            cls_pred_name = class_names[cls_pred[i]]\n",
    "\n",
    "            xlabel = \"True: {0}\\nPred: {1}\".format(cls_true_name, cls_pred_name)\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_images(images_train[1:10,:,:,:], cls_train[1:10,:], cls_pred=None, smooth=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
