{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants describing the training process.\n",
    "img_size_cropped =24\n",
    "num_channels = 3\n",
    "num_classes = 10\n",
    "\n",
    "batch_size = 256\n",
    "num_iterations = 10000\n",
    "print_unit = 100\n",
    "val_unit = 1000\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has apparently already been downloaded and unpacked.\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_1\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_2\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_3\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_4\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_5\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/test_batch\n"
     ]
    }
   ],
   "source": [
    "# Download and Import Data\n",
    "\n",
    "data_path = \"data/CIFAR-10/\"\n",
    "data_url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "cifar10.maybe_download_and_extract(url=data_url, download_dir=data_path)\n",
    "\n",
    "images_train, cls_train, labels_train = cifar10.load_training_data()\n",
    "images_test, cls_test, labels_test = cifar10.load_test_data()\n",
    "\n",
    "## For Debugging\n",
    "# images_train = images_train[0:100,:,:,:]\n",
    "# images_test = images_test[0:10,:,:,:]\n",
    "# labels_train = labels_train[0:100,:]\n",
    "# labels_test = labels_test[0:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "def pre_process_image(image, training):\n",
    "\n",
    "    if training:\n",
    "        \n",
    "        image = tf.random_crop(image, size=[img_size_cropped, img_size_cropped, num_channels])\n",
    "        \n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "        image = tf.image.random_contrast(image, lower=0.3, upper=1.0)\n",
    "        image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "        image = tf.image.random_saturation(image, lower=0.0, upper=2.0)\n",
    "\n",
    "        image = tf.minimum(image, 1.0)\n",
    "        image = tf.maximum(image, 0.0)\n",
    "\n",
    "    else:\n",
    "\n",
    "        image = tf.image.resize_image_with_crop_or_pad(image,\n",
    "                                                       target_height=img_size_cropped,\n",
    "                                                       target_width=img_size_cropped)\n",
    "\n",
    "    return image\n",
    "\n",
    "def pre_process(images, training):\n",
    "\n",
    "    images = tf.map_fn(lambda image: pre_process_image(image, training), images)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "def random_batch():\n",
    "    # Number of images in the training-set.\n",
    "    num_images = len(images_train)\n",
    "    \n",
    "    # Create a random index.\n",
    "    idx = np.random.choice(num_images,\n",
    "                           size=batch_size,\n",
    "                           replace=False)\n",
    "\n",
    "    # Use the random index to select random images and labels.\n",
    "    x_batch = images_train[idx,:,:,:]\n",
    "    y_batch = labels_train[idx, :]\n",
    "\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "def _variable_with_weight_decay(name, shape, stddev, wd):\n",
    "    \"\"\"\n",
    "    Helper to create an initialized Variable with weight decay\n",
    "\n",
    "    Args:\n",
    "        name: name of the variable\n",
    "        shape: list of ints\n",
    "        stddev: standard deviation of a truncated Gaussian\n",
    "        wd: add L2Loss weight decay multiplied by this float. If None, weight\n",
    "            decay is not added for this Variable.\n",
    "\n",
    "    Returns:\n",
    "        Variable Tensor\n",
    "    \"\"\"\n",
    "    var = _variable_on_cpu(\n",
    "        name,\n",
    "        shape,\n",
    "        tf.truncated_normal_initializer(stddev=stddev, dtype=tf.float32))\n",
    "    if wd is not None:\n",
    "        weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "        tf.add_to_collection('losses', weight_decay)\n",
    "    return var\n",
    "\n",
    "\n",
    "def _variable_on_cpu(name, shape, initializer):\n",
    "    \"\"\"\n",
    "    Helper to create a Variable stored on CPU memory\n",
    "\n",
    "    Args:\n",
    "        name: name of the variable\n",
    "        shape: list of ints\n",
    "        initializer: initializer for Variable\n",
    "\n",
    "    Returns:\n",
    "        Variable Tensor\n",
    "\n",
    "    \"\"\"\n",
    "    with tf.device('/cpu:0'):\n",
    "        var = tf.get_variable(name, shape, initializer=initializer, dtype=tf.float32)\n",
    "    return var\n",
    "\n",
    "def compute_logits_cnn(x):\n",
    "    \n",
    "    phase_train = tf.placeholder(tf.bool, name='phase_train')\n",
    "\n",
    "    x = tf.reshape(x, [-1, img_size_cropped, img_size_cropped, 3])\n",
    "\n",
    "    # layer_conv1\n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "        kernel = _variable_with_weight_decay('weights',\n",
    "                                             shape=[5, 5, 3, 64],\n",
    "                                             stddev=5e-2,\n",
    "                                             wd=0.0)\n",
    "        conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0))\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "\n",
    "    # batch normalize\n",
    "    batch_mean, batch_var = tf.nn.moments(conv1, [0])\n",
    "    scale = tf.Variable(tf.ones([64]))\n",
    "    beta = tf.Variable(tf.zeros([64]))\n",
    "    bn1 = tf.nn.batch_normalization(conv1, batch_mean, batch_var,\n",
    "                                    beta, scale, 1e-3)\n",
    "    # max_pool\n",
    "    pool1 = tf.nn.max_pool(bn1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='SAME', name='pool1')\n",
    "\n",
    "    # layer_conv2\n",
    "    with tf.variable_scope('conv2') as scope:\n",
    "        kernel = _variable_with_weight_decay('weights',\n",
    "                                             shape=[5, 5, 64, 64],\n",
    "                                             stddev=5e-2,\n",
    "                                             wd=0.0)\n",
    "        conv = tf.nn.conv2d(pool1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0))\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv2 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "\n",
    "    # batch normalize\n",
    "    batch_mean, batch_var = tf.nn.moments(conv2, [0])\n",
    "    scale = tf.Variable(tf.ones([64]))\n",
    "    beta = tf.Variable(tf.zeros([64]))\n",
    "    bn2 = tf.nn.batch_normalization(conv2, batch_mean, batch_var,\n",
    "                                    beta, scale, 1e-3)\n",
    "\n",
    "    # max_pool\n",
    "    pool2 = tf.nn.max_pool(bn2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='SAME', name='pool1')\n",
    "    \n",
    "    # layer_fc1\n",
    "    with tf.variable_scope('fc1') as scope:\n",
    "        # flatten\n",
    "        reshape = tf.reshape(pool2, [-1, 6*6*64])\n",
    "        dim = reshape.get_shape()[1].value\n",
    "        weights = _variable_with_weight_decay('weights', shape=[dim, 256],\n",
    "                                              stddev=0.04, wd=0.0)\n",
    "        biases = _variable_on_cpu('biases', [256], tf.constant_initializer(0.0))\n",
    "        fc1 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)\n",
    "\n",
    "    # layer_fc2\n",
    "    with tf.variable_scope('fc2') as scope:\n",
    "        weights = _variable_with_weight_decay('weights', shape=[256, 128],\n",
    "                                              stddev=0.04, wd=0.0)\n",
    "        biases = _variable_on_cpu('biases', [128], tf.constant_initializer(0.0))\n",
    "        fc2 = tf.nn.relu(tf.matmul(fc1, weights) + biases, name=scope.name)\n",
    "\n",
    "    # softmax_classifier\n",
    "    with tf.variable_scope('softmax_linear') as scope:\n",
    "        weights = _variable_with_weight_decay('weights', [128, num_classes],\n",
    "                                          stddev=1/128.0, wd=0.0)\n",
    "        biases = _variable_on_cpu('biases', [num_classes],\n",
    "                              tf.constant_initializer(0.0))\n",
    "        softmax_linear = tf.add(tf.matmul(fc2, weights), biases, name=scope.name)   \n",
    "\n",
    "    return softmax_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "def compute_cross_entropy(logits, y):\n",
    "    sm_ce = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits, name='cross_ent_terms')\n",
    "    cross_ent = tf.reduce_mean(sm_ce, name='cross_ent')\n",
    "    return cross_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "def compute_accuracy(logits, y):\n",
    "    prediction = tf.argmax(logits, 1, name='pred_class')\n",
    "    true_label = tf.argmax(y, 1, name='true_class')\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, true_label), tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to restore last checkpoint ...\n",
      "INFO:tensorflow:Restoring parameters from ./model/model_iter-220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/model_iter-220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from: ./model/model_iter-220\n",
      "Step   0: training accuracy 0.3086\n",
      "Step   0: training loss 1.8160\n",
      "Step   0: val accuracy 0.3215\n",
      "Step   0: val loss 1.8380\n",
      "Step 100: training accuracy 0.3711\n",
      "Step 100: training loss 1.7926\n",
      "Step 200: training accuracy 0.3750\n",
      "Step 200: training loss 1.6487\n",
      "Step 300: training accuracy 0.3984\n",
      "Step 300: training loss 1.6969\n",
      "Step 400: training accuracy 0.4258\n",
      "Step 400: training loss 1.6352\n",
      "Step 500: training accuracy 0.4961\n",
      "Step 500: training loss 1.5216\n",
      "Step 600: training accuracy 0.4297\n",
      "Step 600: training loss 1.5921\n",
      "Step 700: training accuracy 0.4492\n",
      "Step 700: training loss 1.4976\n",
      "Step 800: training accuracy 0.4688\n",
      "Step 800: training loss 1.5416\n",
      "Step 900: training accuracy 0.4883\n",
      "Step 900: training loss 1.5529\n",
      "Step 1000: training accuracy 0.4180\n",
      "Step 1000: training loss 1.6560\n",
      "Step 1000: val accuracy 0.4742\n",
      "Step 1000: val loss 1.4852\n",
      "Step 1100: training accuracy 0.4883\n",
      "Step 1100: training loss 1.4161\n",
      "Step 1200: training accuracy 0.5078\n",
      "Step 1200: training loss 1.4308\n",
      "Step 1300: training accuracy 0.5312\n",
      "Step 1300: training loss 1.4267\n",
      "Step 1400: training accuracy 0.5078\n",
      "Step 1400: training loss 1.3843\n",
      "Step 1500: training accuracy 0.5195\n",
      "Step 1500: training loss 1.4549\n",
      "Step 1600: training accuracy 0.4883\n",
      "Step 1600: training loss 1.3427\n",
      "Step 1700: training accuracy 0.5547\n",
      "Step 1700: training loss 1.3246\n",
      "Step 1800: training accuracy 0.5234\n",
      "Step 1800: training loss 1.3892\n",
      "Step 1900: training accuracy 0.5156\n",
      "Step 1900: training loss 1.3973\n",
      "Step 2000: training accuracy 0.5859\n",
      "Step 2000: training loss 1.2944\n",
      "Step 2000: val accuracy 0.5296\n",
      "Step 2000: val loss 1.3504\n",
      "Step 2100: training accuracy 0.5469\n",
      "Step 2100: training loss 1.3634\n",
      "Step 2200: training accuracy 0.5508\n",
      "Step 2200: training loss 1.2320\n",
      "Step 2300: training accuracy 0.5742\n",
      "Step 2300: training loss 1.2763\n",
      "Step 2400: training accuracy 0.5117\n",
      "Step 2400: training loss 1.2858\n",
      "Step 2500: training accuracy 0.5391\n",
      "Step 2500: training loss 1.2967\n",
      "Step 2600: training accuracy 0.5078\n",
      "Step 2600: training loss 1.2957\n",
      "Step 2700: training accuracy 0.6211\n",
      "Step 2700: training loss 1.1284\n",
      "Step 2800: training accuracy 0.5547\n",
      "Step 2800: training loss 1.2904\n",
      "Step 2900: training accuracy 0.5547\n",
      "Step 2900: training loss 1.2067\n",
      "Step 3000: training accuracy 0.5312\n",
      "Step 3000: training loss 1.3115\n",
      "Step 3000: val accuracy 0.5572\n",
      "Step 3000: val loss 1.2638\n",
      "Step 3100: training accuracy 0.6055\n",
      "Step 3100: training loss 1.1795\n",
      "Step 3200: training accuracy 0.5586\n",
      "Step 3200: training loss 1.2889\n",
      "Step 3300: training accuracy 0.5352\n",
      "Step 3300: training loss 1.2589\n",
      "Step 3400: training accuracy 0.5312\n",
      "Step 3400: training loss 1.3254\n",
      "Step 3500: training accuracy 0.5625\n",
      "Step 3500: training loss 1.2553\n",
      "Step 3600: training accuracy 0.6289\n",
      "Step 3600: training loss 1.0748\n",
      "Step 3700: training accuracy 0.6562\n",
      "Step 3700: training loss 1.0547\n",
      "Step 3800: training accuracy 0.6172\n",
      "Step 3800: training loss 1.1410\n",
      "Step 3900: training accuracy 0.6055\n",
      "Step 3900: training loss 1.1676\n",
      "Step 4000: training accuracy 0.5977\n",
      "Step 4000: training loss 1.1857\n",
      "Step 4000: val accuracy 0.5781\n",
      "Step 4000: val loss 1.2019\n",
      "Step 4100: training accuracy 0.5938\n",
      "Step 4100: training loss 1.1672\n",
      "Step 4200: training accuracy 0.6133\n",
      "Step 4200: training loss 1.1991\n",
      "Step 4300: training accuracy 0.6797\n",
      "Step 4300: training loss 1.0196\n",
      "Step 4400: training accuracy 0.6758\n",
      "Step 4400: training loss 1.0282\n",
      "Step 4500: training accuracy 0.6484\n",
      "Step 4500: training loss 1.0830\n",
      "Step 4600: training accuracy 0.6289\n",
      "Step 4600: training loss 1.1027\n",
      "Step 4700: training accuracy 0.6367\n",
      "Step 4700: training loss 1.1121\n",
      "Step 4800: training accuracy 0.5781\n",
      "Step 4800: training loss 1.1727\n",
      "Step 4900: training accuracy 0.6055\n",
      "Step 4900: training loss 1.0762\n",
      "Step 5000: training accuracy 0.5938\n",
      "Step 5000: training loss 1.1666\n",
      "Step 5000: val accuracy 0.5944\n",
      "Step 5000: val loss 1.1616\n",
      "Step 5100: training accuracy 0.5898\n",
      "Step 5100: training loss 1.1789\n",
      "Step 5200: training accuracy 0.6445\n",
      "Step 5200: training loss 0.9919\n",
      "Step 5300: training accuracy 0.5938\n",
      "Step 5300: training loss 1.1756\n",
      "Step 5400: training accuracy 0.5977\n",
      "Step 5400: training loss 1.1438\n",
      "Step 5500: training accuracy 0.6094\n",
      "Step 5500: training loss 1.1350\n",
      "Step 5600: training accuracy 0.6289\n",
      "Step 5600: training loss 1.1074\n",
      "Step 5700: training accuracy 0.6289\n",
      "Step 5700: training loss 1.1224\n",
      "Step 5800: training accuracy 0.6016\n",
      "Step 5800: training loss 1.1314\n",
      "Step 5900: training accuracy 0.6836\n",
      "Step 5900: training loss 0.9503\n",
      "Step 6000: training accuracy 0.6484\n",
      "Step 6000: training loss 0.9961\n",
      "Step 6000: val accuracy 0.6134\n",
      "Step 6000: val loss 1.1154\n",
      "Step 6100: training accuracy 0.6406\n",
      "Step 6100: training loss 1.0928\n",
      "Step 6200: training accuracy 0.6055\n",
      "Step 6200: training loss 1.1533\n",
      "Step 6300: training accuracy 0.5898\n",
      "Step 6300: training loss 1.1374\n",
      "Step 6400: training accuracy 0.6484\n",
      "Step 6400: training loss 1.0371\n",
      "Step 6500: training accuracy 0.6562\n",
      "Step 6500: training loss 0.9889\n",
      "Step 6600: training accuracy 0.6406\n",
      "Step 6600: training loss 1.0279\n",
      "Step 6700: training accuracy 0.6445\n",
      "Step 6700: training loss 0.9657\n",
      "Step 6800: training accuracy 0.6445\n",
      "Step 6800: training loss 1.0433\n",
      "Step 6900: training accuracy 0.6953\n",
      "Step 6900: training loss 0.9393\n",
      "Step 7000: training accuracy 0.6680\n",
      "Step 7000: training loss 0.9743\n",
      "Step 7000: val accuracy 0.6224\n",
      "Step 7000: val loss 1.0741\n",
      "Step 7100: training accuracy 0.6992\n",
      "Step 7100: training loss 0.8561\n",
      "Step 7200: training accuracy 0.6445\n",
      "Step 7200: training loss 1.0907\n",
      "Step 7300: training accuracy 0.6484\n",
      "Step 7300: training loss 1.0915\n",
      "Step 7400: training accuracy 0.6133\n",
      "Step 7400: training loss 1.0831\n",
      "Step 7500: training accuracy 0.6016\n",
      "Step 7500: training loss 1.0684\n",
      "Step 7600: training accuracy 0.6484\n",
      "Step 7600: training loss 1.0448\n",
      "Step 7700: training accuracy 0.6602\n",
      "Step 7700: training loss 0.9092\n",
      "Step 7800: training accuracy 0.6562\n",
      "Step 7800: training loss 0.9921\n",
      "Step 7900: training accuracy 0.6367\n",
      "Step 7900: training loss 0.9908\n",
      "Step 8000: training accuracy 0.6836\n",
      "Step 8000: training loss 0.9364\n",
      "Step 8000: val accuracy 0.6359\n",
      "Step 8000: val loss 1.0541\n",
      "Step 8100: training accuracy 0.6133\n",
      "Step 8100: training loss 1.1097\n",
      "Step 8200: training accuracy 0.6445\n",
      "Step 8200: training loss 1.0256\n",
      "Step 8300: training accuracy 0.6797\n",
      "Step 8300: training loss 0.9098\n",
      "Step 8400: training accuracy 0.6797\n",
      "Step 8400: training loss 0.9136\n",
      "Step 8500: training accuracy 0.6797\n",
      "Step 8500: training loss 0.9401\n",
      "Step 8600: training accuracy 0.6445\n",
      "Step 8600: training loss 0.9479\n",
      "Step 8700: training accuracy 0.6797\n",
      "Step 8700: training loss 0.9640\n",
      "Step 8800: training accuracy 0.6289\n",
      "Step 8800: training loss 1.0778\n",
      "Step 8900: training accuracy 0.6484\n",
      "Step 8900: training loss 1.0390\n",
      "Step 9000: training accuracy 0.6328\n",
      "Step 9000: training loss 1.0337\n",
      "Step 9000: val accuracy 0.6469\n",
      "Step 9000: val loss 1.0175\n",
      "Step 9100: training accuracy 0.6797\n",
      "Step 9100: training loss 0.9095\n",
      "Step 9200: training accuracy 0.6094\n",
      "Step 9200: training loss 1.0646\n",
      "Step 9300: training accuracy 0.6797\n",
      "Step 9300: training loss 0.9030\n",
      "Step 9400: training accuracy 0.6406\n",
      "Step 9400: training loss 1.0325\n",
      "Step 9500: training accuracy 0.6758\n",
      "Step 9500: training loss 0.9457\n",
      "Step 9600: training accuracy 0.6641\n",
      "Step 9600: training loss 1.0139\n",
      "Step 9700: training accuracy 0.6602\n",
      "Step 9700: training loss 0.9812\n",
      "Step 9800: training accuracy 0.6406\n",
      "Step 9800: training loss 1.0444\n",
      "Step 9900: training accuracy 0.6836\n",
      "Step 9900: training loss 0.9270\n",
      "INFO:tensorflow:No assets to save.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'savedmodel_12_14_22_15_0/saved_model.pb'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'savedmodel_12_14_22_15_0/saved_model.pb'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'savedmodel_12_14_22_15_0/saved_model.pb'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN\n",
    "now = datetime.now()\n",
    "dir_name = 'log_{0}_{1}'.format(now.month,now.day)\n",
    "export_dir = 'savedmodel_{0}_{1}_{2}_{3}_{4}'.format(now.month,now.day,now.hour,now.minute,now.second)\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(export_dir)\n",
    "with tf.Graph().as_default():\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    with tf.device('/cpu:0'):\n",
    "        x = tf.placeholder(tf.float32, shape=[None, 32, 32, num_channels], name='x')\n",
    "        y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "\n",
    "        images = pre_process(images=x, training=True)\n",
    "\n",
    "    with tf.name_scope('model'):\n",
    "        logits = compute_logits_cnn(images)\n",
    "\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = compute_cross_entropy(logits=logits, y=y_true)\n",
    "\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = compute_accuracy(logits=logits, y=y_true)\n",
    "\n",
    "    with tf.name_scope('opt'):\n",
    "        opt = tf.train.AdamOptimizer(learning_rate)\n",
    "        train_step = opt.minimize(loss)\n",
    "\n",
    "    with tf.name_scope('summaries'):\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "        tf.summary.histogram('logit', logits)\n",
    "        tf.summary.image('input', tf.reshape(images, [-1, img_size_cropped, img_size_cropped, num_channels]))\n",
    "        summary_op = tf.summary.merge_all()\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    sess = tf.Session()\n",
    "    summary_writer = tf.summary.FileWriter(dir_name, sess.graph)\n",
    "    summary_writer_train = tf.summary.FileWriter(dir_name+'/train', sess.graph)\n",
    "    summary_writer_val = tf.summary.FileWriter(dir_name+'/val')\n",
    "\n",
    "    try:\n",
    "        print(\"Trying to restore last checkpoint ...\")\n",
    "\n",
    "        # Use TensorFlow to find the latest checkpoint - if any.\n",
    "        last_chk_path = tf.train.latest_checkpoint(checkpoint_dir='./model/')\n",
    "\n",
    "        # Try and load the data in the checkpoint.\n",
    "        saver.restore(sess, save_path=last_chk_path)\n",
    "\n",
    "        # If we get to this point, the checkpoint was successfully loaded.\n",
    "        print(\"Restored checkpoint from:\", last_chk_path)\n",
    "    except:\n",
    "        # If the above failed for some reason, simply\n",
    "        # initialize all the variables for the TensorFlow graph.\n",
    "        print(\"Failed to restore checkpoint. Initializing variables instead.\")\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        X_batch, y_batch = random_batch()\n",
    "\n",
    "        _, summary = sess.run((train_step, summary_op),\n",
    "                                feed_dict={x: X_batch, y_true: y_batch})\n",
    "\n",
    "        if i%print_unit==0:\n",
    "            summary_writer_train.add_summary(summary, i)\n",
    "                \n",
    "            (train_error, train_accuracy, train_logits) = sess.run((loss, accuracy, logits), {x: X_batch, y_true: y_batch})\n",
    "            print(\"\\rStep {0:3d}: training accuracy {1:0.4f}\".format(i, train_accuracy), flush=True)\n",
    "            print(\"\\rStep {0:3d}: training loss {1:0.4f}\".format(i, train_error), flush=True)\n",
    "        if (i+1)%val_unit == 0:\n",
    "            (val_error, val_accuracy, summary) = sess.run((loss, accuracy,summary_op), {x:images_test, y_true:labels_test})\n",
    "            print(\"\\rStep {0:3d}: val accuracy {1:0.4f}\".format(i, val_accuracy), flush=True)\n",
    "            print(\"\\rStep {0:3d}: val loss {1:0.4f}\".format(i, val_error), flush=True)\n",
    "            summary_writer_val.add_summary(summary, i)\n",
    "            saver.save(sess, './model/model_iter', global_step=i)\n",
    "\n",
    "    save_path = saver.save(sess, \"./model/final_model.ckpt\")\n",
    "    builder.add_meta_graph_and_variables(sess, [\"foo-tag\"])\n",
    "\n",
    "builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
